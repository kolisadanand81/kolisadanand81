{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Load a CSV file into a DataFrame\n",
        "\n",
        "**Expected Result:** Shows first 5 rows of the Airlines dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/databricks-datasets/airlines/part-00000\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Cache a DataFrame for faster access\n",
        "\n",
        "**Expected Result:** Caches the DataFrame into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.cache()\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Select specific columns from a DataFrame\n",
        "\n",
        "**Expected Result:** Shows selected columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select(\"Year\", \"Month\", \"DepDelay\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: Filter rows where DepDelay > 30 minutes\n",
        "\n",
        "**Expected Result:** Shows flights delayed more than 30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.filter(df.DepDelay > 30).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5: Add a new column 'DelayCategory'\n",
        "\n",
        "**Expected Result:** Adds column categorizing flights as Late or OnTime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "df2 = df.withColumn(\"DelayCategory\", when(df.DepDelay > 30, \"Late\").otherwise(\"OnTime\"))\n",
        "df2.select(\"DepDelay\", \"DelayCategory\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6: Group by Origin and count flights\n",
        "\n",
        "**Expected Result:** Shows airports with most flights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupBy(\"Origin\").count().orderBy(\"count\", ascending=False).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 7: Sort flights by Departure Delay descending\n",
        "\n",
        "**Expected Result:** Flights with highest departure delay first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.orderBy(df.DepDelay.desc()).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 8: Rename column DepDelay to DepartureDelayMinutes\n",
        "\n",
        "**Expected Result:** Column renamed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = df.withColumnRenamed(\"DepDelay\", \"DepartureDelayMinutes\")\n",
        "df2.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 9: Drop rows with null DepDelay\n",
        "\n",
        "**Expected Result:** Null DepDelay rows removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = df.na.drop(subset=[\"DepDelay\"])\n",
        "df_clean.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 10: Get distinct Origin airports\n",
        "\n",
        "**Expected Result:** Lists distinct origin airports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select(\"Origin\").distinct().show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 11: Save DataFrame as Delta Table\n",
        "\n",
        "**Expected Result:** Saves as Delta format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/airlines_delta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 12: Load Delta Table into DataFrame\n",
        "\n",
        "**Expected Result:** Loads Delta format back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_delta = spark.read.format(\"delta\").load(\"/tmp/airlines_delta\")\n",
        "df_delta.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 13: Create a SQL table from Delta location\n",
        "\n",
        "**Expected Result:** Creates SQL table linked to Delta files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"CREATE TABLE IF NOT EXISTS airlines_delta USING DELTA LOCATION '/tmp/airlines_delta'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 14: Update records in Delta Table\n",
        "\n",
        "**Expected Result:** Updates NULL DepDelay values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"UPDATE airlines_delta SET DepDelay = 0 WHERE DepDelay IS NULL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 15: Time Travel to old Delta Table version\n",
        "\n",
        "**Expected Result:** Reads earlier version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_old = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/tmp/airlines_delta\")\n",
        "df_old.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 16: Merge new data into Delta Table\n",
        "\n",
        "**Expected Result:** Upserts data into Delta Table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from delta.tables import DeltaTable\n",
        "\n",
        "deltaTable = DeltaTable.forPath(spark, \"/tmp/airlines_delta\")\n",
        "deltaTable.alias(\"old\").merge(\n",
        "    df.alias(\"new\"), \"old.FlightNum = new.FlightNum\"\n",
        ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 17: Optimize Delta Table\n",
        "\n",
        "**Expected Result:** Improves Delta query speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"OPTIMIZE airlines_delta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 18: Vacuum old files from Delta Table\n",
        "\n",
        "**Expected Result:** Cleans up old files safely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"VACUUM airlines_delta RETAIN 168 HOURS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 19: Add a new column to Delta Table\n",
        "\n",
        "**Expected Result:** New column added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"ALTER TABLE airlines_delta ADD COLUMNS (NewColumn STRING)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 20: Drop a column from Delta Table\n",
        "\n",
        "**Expected Result:** Column removed from Delta Table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"ALTER TABLE airlines_delta DROP COLUMN NewColumn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 21: Run SQL query on Delta Table\n",
        "\n",
        "**Expected Result:** Average delays per Carrier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT Carrier, AVG(DepDelay) AS AvgDepDelay FROM airlines_delta GROUP BY Carrier ORDER BY AvgDepDelay DESC\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 22: Create managed Delta Table from DataFrame\n",
        "\n",
        "**Expected Result:** Creates managed SQL table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.write.saveAsTable(\"managed_airlines_table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 23: Drop SQL table\n",
        "\n",
        "**Expected Result:** Deletes SQL table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"DROP TABLE IF EXISTS managed_airlines_table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 24: Create a temporary SQL View\n",
        "\n",
        "**Expected Result:** Creates view for easy querying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"temp_view_flights\")\n",
        "spark.sql(\"SELECT * FROM temp_view_flights LIMIT 5\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 25: Check Delta Table history\n",
        "\n",
        "**Expected Result:** Shows table modification history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"DESCRIBE HISTORY airlines_delta\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 26: Top 5 flights with highest Arrival Delay\n",
        "\n",
        "**Expected Result:** Top delayed flights displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.orderBy(df.ArrDelay.desc()).select(\"FlightNum\", \"ArrDelay\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 27: Find flights with negative DepDelay (early departures)\n",
        "\n",
        "**Expected Result:** Early departing flights listed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.filter(df.DepDelay < 0).select(\"FlightNum\", \"DepDelay\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 28: Group by Carrier and calculate avg DepDelay\n",
        "\n",
        "**Expected Result:** Best and worst airlines by delay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupBy(\"Carrier\").avg(\"DepDelay\").orderBy(\"avg(DepDelay)\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 29: Register DataFrame as SQL Table then query\n",
        "\n",
        "**Expected Result:** Top airports displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"airport_summary\")\n",
        "spark.sql(\"SELECT Origin, COUNT(*) FROM airport_summary GROUP BY Origin ORDER BY COUNT(*) DESC\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 30: Perform Delta Time Travel using SQL\n",
        "\n",
        "**Expected Result:** Reads old snapshot of table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT * FROM airlines_delta VERSION AS OF 0 LIMIT 5\").show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
